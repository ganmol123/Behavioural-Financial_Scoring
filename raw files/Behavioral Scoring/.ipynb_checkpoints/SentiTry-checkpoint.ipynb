{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk \n",
    "import io \n",
    "import unicodedata \n",
    "import numpy as np \n",
    "import re \n",
    "import string \n",
    "from numpy import linalg \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.tokenize import PunktSentenceTokenizer \n",
    "from nltk.tokenize import PunktSentenceTokenizer \n",
    "from nltk.corpus import webtext \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import requests \n",
    "import os, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am going to kill you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(text):\n",
    "    sent_tokenizer = PunktSentenceTokenizer(text) \n",
    "    sents = sent_tokenizer.tokenize(text) \n",
    "\n",
    "    word_tokenize(text)\n",
    "    sent_tokenize(text)\n",
    "\n",
    "    porter_stemmer = PorterStemmer() \n",
    "  \n",
    "    nltk_tokens = nltk.word_tokenize(text) \n",
    "  \n",
    "    for w in nltk_tokens: \n",
    "        porter_stemmer.stem(w)\n",
    "  \n",
    "    wordnet_lemmatizer = WordNetLemmatizer() \n",
    "    nltk_tokens = nltk.word_tokenize(text) \n",
    "  \n",
    "    for w in nltk_tokens: \n",
    "        wordnet_lemmatizer.lemmatize(w)\n",
    "      \n",
    "    text = nltk.word_tokenize(text) \n",
    "    nltk.pos_tag(text)\n",
    "  \n",
    "    sid = SentimentIntensityAnalyzer()  \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') \n",
    "    \n",
    "    for line in text:\n",
    "        print(line) \n",
    "        scores = sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "compound: 0.0, neg: 0.0, neu: 0.0, pos: 0.0, am\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, going\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, to\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, kill\n",
      "compound: -0.6908, neg: 1.0, neu: 0.0, pos: 0.0, you\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "func(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
